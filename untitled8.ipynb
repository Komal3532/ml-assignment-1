{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBdOGAQGsCMA",
        "outputId": "8310403e-323b-4cf7-c8f4-14c28f84fbf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array:\n",
            " [[39 29 15 43]\n",
            " [ 8 21 39 19]\n",
            " [23 11 11 24]\n",
            " [36 40 24  3]\n",
            " [22  2 24 44]]\n",
            "Anti-diagonal: [np.int64(43), np.int64(39), np.int64(11), np.int64(36)]\n",
            "Max values in each row: [43 39 24 40 44]\n",
            "Elements ≤ mean: [15  8 21 19 23 11 11  3 22  2]\n",
            "Boundary traversal: [np.int64(39), np.int64(29), np.int64(15), np.int64(43), np.int64(19), np.int64(24), np.int64(3), np.int64(44), np.int64(24), np.int64(2), np.int64(22), np.int64(36), np.int64(23), np.int64(8)]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate array\n",
        "array_2d = np.random.randint(1, 51, size=(5, 4))\n",
        "print(\"Array:\\n\", array_2d)\n",
        "\n",
        "anti_diag = [array_2d[i, -1 - i] for i in range(min(array_2d.shape))]\n",
        "print(\"Anti-diagonal:\", anti_diag)\n",
        "\n",
        "# Max in each row\n",
        "row_max = np.max(array_2d, axis=1)\n",
        "print(\"Max values in each row:\", row_max)\n",
        "\n",
        "# Elements <= overall mean\n",
        "mean_val = np.mean(array_2d)\n",
        "less_than_mean = array_2d[array_2d <= mean_val]\n",
        "print(\"Elements ≤ mean:\", less_than_mean)\n",
        "\n",
        "# Boundary traversal\n",
        "def numpy_boundary_traversal(matrix):\n",
        "    return list(matrix[0]) + list(matrix[1:-1, -1]) + list(matrix[-1][::-1]) + list(matrix[-2:0:-1, 0])\n",
        "\n",
        "print(\"Boundary traversal:\", numpy_boundary_traversal(array_2d))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1D array of random floats\n",
        "array_1d = np.random.uniform(0, 10, 20)\n",
        "array_rounded = np.round(array_1d, 2)\n",
        "print(\"Rounded array:\", array_rounded)\n",
        "\n",
        "# Statistics\n",
        "print(\"Min:\", np.min(array_rounded))\n",
        "print(\"Max:\", np.max(array_rounded))\n",
        "print(\"Median:\", np.median(array_rounded))\n",
        "\n",
        "# Replace < 5 with squares\n",
        "modified_array = np.where(array_rounded < 5, array_rounded**2, array_rounded)\n",
        "print(\"Modified array:\", modified_array)\n",
        "\n",
        "# Alternate sort\n",
        "def numpy_alternate_sort(array):\n",
        "    sorted_array = np.sort(array)\n",
        "    result = []\n",
        "    left, right = 0, len(sorted_array) - 1\n",
        "    while left <= right:\n",
        "        result.append(sorted_array[left])\n",
        "        left += 1\n",
        "        if left <= right:\n",
        "            result.append(sorted_array[right])\n",
        "            right -= 1\n",
        "    return np.array(result)\n",
        "\n",
        "print(\"Alternate sorted array:\", numpy_alternate_sort(array_rounded))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYBr7eGHs2lp",
        "outputId": "23653e8d-71e1-4929-e607-1f6ace1d6b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rounded array: [9.39 0.01 9.92 6.17 6.12 0.07 0.23 5.25 4.   0.47 9.74 2.33 0.91 6.18\n",
            " 3.82 9.83 4.67 8.6  6.8  4.5 ]\n",
            "Min: 0.01\n",
            "Max: 9.92\n",
            "Median: 4.96\n",
            "Modified array: [9.39000e+00 1.00000e-04 9.92000e+00 6.17000e+00 6.12000e+00 4.90000e-03\n",
            " 5.29000e-02 5.25000e+00 1.60000e+01 2.20900e-01 9.74000e+00 5.42890e+00\n",
            " 8.28100e-01 6.18000e+00 1.45924e+01 9.83000e+00 2.18089e+01 8.60000e+00\n",
            " 6.80000e+00 2.02500e+01]\n",
            "Alternate sorted array: [0.01 9.92 0.07 9.83 0.23 9.74 0.47 9.39 0.91 8.6  2.33 6.8  3.82 6.18\n",
            " 4.   6.17 4.5  6.12 4.67 5.25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "names = [f\"Student{i}\" for i in range(1, 11)]\n",
        "subjects = random.choices(['Math', 'Science', 'English'], k=10)\n",
        "scores = np.random.randint(50, 101, 10)\n",
        "\n",
        "# Grade assignment\n",
        "grades = []\n",
        "for score in scores:\n",
        "    if score >= 90: grades.append(\"A\")\n",
        "    elif score >= 80: grades.append(\"B\")\n",
        "    elif score >= 70: grades.append(\"C\")\n",
        "    elif score >= 60: grades.append(\"D\")\n",
        "    else: grades.append(\"F\")\n",
        "\n",
        "df = pd.DataFrame({'Name': names, 'Subject': subjects, 'Score': scores, 'Grade': grades})\n",
        "print(df)\n",
        "\n",
        "# Sorted DataFrame\n",
        "print(\"Sorted by Score:\\n\", df.sort_values(by='Score', ascending=False))\n",
        "\n",
        "# Average score by subject\n",
        "print(\"Average score per subject:\\n\", df.groupby('Subject')['Score'].mean())\n",
        "\n",
        "# Filter function\n",
        "def pandas_filter_pass(dataframe):\n",
        "    return dataframe[dataframe['Grade'].isin(['A', 'B'])]\n",
        "\n",
        "print(\"Students with A or B:\\n\", pandas_filter_pass(df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ESdz_m1tB09",
        "outputId": "b1332699-eda1-4757-ec6b-f6a0ca4578d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Name  Subject  Score Grade\n",
            "0   Student1  Science     67     D\n",
            "1   Student2  English     53     F\n",
            "2   Student3     Math     74     C\n",
            "3   Student4     Math     63     D\n",
            "4   Student5     Math     99     A\n",
            "5   Student6  English     58     F\n",
            "6   Student7     Math     75     C\n",
            "7   Student8  English     51     F\n",
            "8   Student9  English     69     D\n",
            "9  Student10  English     77     C\n",
            "Sorted by Score:\n",
            "         Name  Subject  Score Grade\n",
            "4   Student5     Math     99     A\n",
            "9  Student10  English     77     C\n",
            "6   Student7     Math     75     C\n",
            "2   Student3     Math     74     C\n",
            "8   Student9  English     69     D\n",
            "0   Student1  Science     67     D\n",
            "3   Student4     Math     63     D\n",
            "5   Student6  English     58     F\n",
            "1   Student2  English     53     F\n",
            "7   Student8  English     51     F\n",
            "Average score per subject:\n",
            " Subject\n",
            "English    61.60\n",
            "Math       77.75\n",
            "Science    67.00\n",
            "Name: Score, dtype: float64\n",
            "Students with A or B:\n",
            "        Name Subject  Score Grade\n",
            "4  Student5    Math     99     A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create synthetic dataset\n",
        "np.random.seed(42)\n",
        "\n",
        "# Positive reviews\n",
        "positive_reviews = [\n",
        "    \"This movie was absolutely fantastic! The acting was superb.\",\n",
        "    \"I loved every minute of this film. The plot was engaging.\",\n",
        "    \"A masterpiece of cinema that will stand the test of time.\",\n",
        "    \"The director did an amazing job with this production.\",\n",
        "    \"One of the best movies I've seen this year, highly recommended!\",\n",
        "    \"The cinematography was breathtaking and the story compelling.\",\n",
        "    \"A perfect blend of action, drama, and comedy. Wonderful!\",\n",
        "    \"The performances were outstanding across the board.\",\n",
        "    \"I was completely immersed from start to finish. Brilliant!\",\n",
        "    \"This film exceeded all my expectations. Stunning visuals.\",\n",
        "    \"An emotional rollercoaster that left me speechless.\",\n",
        "    \"The character development was exceptional and moving.\",\n",
        "    \"A true work of art that deserves all the awards.\",\n",
        "    \"I couldn't take my eyes off the screen. Magnificent!\",\n",
        "    \"The soundtrack perfectly complemented the storytelling.\",\n",
        "    \"Fresh and original take on a familiar genre. Loved it!\",\n",
        "    \"The chemistry between the leads was electric.\",\n",
        "    \"A thought-provoking film that stays with you long after.\",\n",
        "    \"Perfect pacing and never a dull moment. Superb!\",\n",
        "    \"The visual effects were groundbreaking and realistic.\",\n",
        "    \"A heartwarming story that touched my soul.\",\n",
        "    \"The dialogue was sharp, witty, and meaningful.\",\n",
        "    \"A cinematic triumph that deserves recognition.\",\n",
        "    \"I laughed, I cried, I cheered. What more could you want?\",\n",
        "    \"The best of its genre in recent memory. Flawless.\",\n",
        "    \"A powerful narrative with incredible performances.\",\n",
        "    \"The atmosphere created was utterly captivating.\",\n",
        "    \"A rare gem that delivers on every level.\",\n",
        "    \"The ending was perfect and deeply satisfying.\",\n",
        "    \"A must-see for any true film enthusiast.\",\n",
        "    \"The attention to detail was remarkable throughout.\",\n",
        "    \"A beautiful film that celebrates the human spirit.\",\n",
        "    \"I was on the edge of my seat the entire time.\",\n",
        "    \"The direction was confident and visionary.\",\n",
        "    \"A refreshing change from typical Hollywood fare.\",\n",
        "    \"The movie had me hooked from the opening scene.\",\n",
        "    \"A perfect balance of style and substance.\",\n",
        "    \"The emotional depth was astonishing. Bravo!\",\n",
        "    \"A film that will be remembered for generations.\",\n",
        "    \"The production design was imaginative and immersive.\",\n",
        "    \"A tour de force that showcases the best of cinema.\",\n",
        "    \"I was completely blown away by this movie.\",\n",
        "    \"The script was clever and full of surprises.\",\n",
        "    \"A moving portrait that resonates deeply.\",\n",
        "    \"The action sequences were thrilling and well-choreographed.\",\n",
        "    \"A profound meditation on life and relationships.\",\n",
        "    \"The humor was spot-on and never felt forced.\",\n",
        "    \"A visually stunning achievement in filmmaking.\",\n",
        "    \"I can't stop thinking about this movie. Phenomenal!\"\n",
        "]\n",
        "\n",
        "# Negative reviews\n",
        "negative_reviews = [\n",
        "    \"This was the worst movie I've ever seen. Terrible acting.\",\n",
        "    \"A complete waste of time. The plot made no sense.\",\n",
        "    \"I couldn't wait for it to end. Painfully boring.\",\n",
        "    \"The dialogue was cringe-worthy and unrealistic.\",\n",
        "    \"Avoid at all costs. A total disaster of a film.\",\n",
        "    \"The characters were unlikeable and poorly developed.\",\n",
        "    \"A soulless cash grab with no originality.\",\n",
        "    \"The pacing was awful and dragged endlessly.\",\n",
        "    \"I walked out halfway through. Just terrible.\",\n",
        "    \"The special effects looked cheap and fake.\",\n",
        "    \"A confusing mess with no coherent storyline.\",\n",
        "    \"The acting was wooden and unconvincing.\",\n",
        "    \"A pretentious attempt at art that falls flat.\",\n",
        "    \"The worst adaptation I've ever witnessed.\",\n",
        "    \"Full of clichés and predictable twists.\",\n",
        "    \"The director clearly had no vision for this project.\",\n",
        "    \"A complete misfire on every possible level.\",\n",
        "    \"I regret spending money on this garbage.\",\n",
        "    \"The soundtrack was distracting and inappropriate.\",\n",
        "    \"A hollow shell of what it could have been.\",\n",
        "    \"The cinematography was dull and uninspired.\",\n",
        "    \"A failed experiment that shouldn't have been released.\",\n",
        "    \"The editing was jarring and inconsistent.\",\n",
        "    \"Not a single redeeming quality in this mess.\",\n",
        "    \"The script was full of plot holes and nonsense.\",\n",
        "    \"A tedious experience with no payoff.\",\n",
        "    \"The lead actor was completely miscast.\",\n",
        "    \"A derivative work with nothing new to offer.\",\n",
        "    \"The humor fell flat every single time.\",\n",
        "    \"A disappointing effort from talented people.\",\n",
        "    \"The production values looked shockingly low.\",\n",
        "    \"A forgettable film that adds nothing to cinema.\",\n",
        "    \"The tone was all over the place and confusing.\",\n",
        "    \"A cynical attempt to cash in on a trend.\",\n",
        "    \"The emotional moments felt forced and unearned.\",\n",
        "    \"A technical disaster with bad sound mixing.\",\n",
        "    \"The runtime felt three times as long as it was.\",\n",
        "    \"A complete misunderstanding of the source material.\",\n",
        "    \"The climax was underwhelming and anticlimactic.\",\n",
        "    \"A movie that insults the audience's intelligence.\",\n",
        "    \"The characters made decisions that made no sense.\",\n",
        "    \"A waste of a talented cast on a bad script.\",\n",
        "    \"The visuals were dated and unimpressive.\",\n",
        "    \"A soulless corporate product with no heart.\",\n",
        "    \"The plot twists were telegraphed from miles away.\",\n",
        "    \"A film that can't decide what it wants to be.\",\n",
        "    \"The ending was unsatisfying and rushed.\",\n",
        "    \"A collection of bad ideas poorly executed.\",\n",
        "    \"The movie couldn't maintain any tension.\",\n",
        "    \"I've never been so bored in a theater before.\"\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "reviews = positive_reviews + negative_reviews\n",
        "sentiments = ['positive'] * len(positive_reviews) + ['negative'] * len(negative_reviews)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Review': reviews,\n",
        "    'Sentiment': sentiments\n",
        "})\n",
        "\n",
        "# Shuffle the dataset\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 1. Tokenize the reviews using CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=500, stop_words='english')\n",
        "X = vectorizer.fit_transform(df['Review'])\n",
        "y = df['Sentiment']\n",
        "\n",
        "# 2. Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train a Multinomial Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model accuracy on test set: {accuracy:.2f}\")\n",
        "\n",
        "# 4. Prediction function\n",
        "def predict_review_sentiment(model, vectorizer, review):\n",
        "    \"\"\"\n",
        "    Predict the sentiment of a single review.\n",
        "\n",
        "    Parameters:\n",
        "    model -- trained classifier model\n",
        "    vectorizer -- fitted CountVectorizer\n",
        "    review -- string containing the review text\n",
        "\n",
        "    Returns:\n",
        "    string -- 'positive' or 'negative' sentiment prediction\n",
        "    \"\"\"\n",
        "    # Vectorize the review\n",
        "    review_vec = vectorizer.transform([review])\n",
        "    # Predict sentiment\n",
        "    prediction = model.predict(review_vec)\n",
        "    return prediction[0]\n",
        "\n",
        "# Example usage\n",
        "test_review = \"This movie was a wonderful experience from start to finish.\"\n",
        "prediction = predict_review_sentiment(model, vectorizer, test_review)\n",
        "print(f\"\\nExample prediction for positive review: {prediction}\")\n",
        "\n",
        "test_review = \"I hated every minute of this awful film.\"\n",
        "prediction = predict_review_sentiment(model, vectorizer, test_review)\n",
        "print(f\"Example prediction for negative review: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXzMJ81kt76o",
        "outputId": "85a5bd1f-506f-4d98-934e-7aaea4d20548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy on test set: 0.50\n",
            "\n",
            "Example prediction for positive review: positive\n",
            "Example prediction for negative review: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pandas as pd # Import pandas\n",
        "\n",
        "\n",
        "\n",
        "# Create a synthetic dataset of 100 short text samples (e.g., product feedback) with binary labels (good/bad)\n",
        "# and apply an NLP pipeline using scikit-learn.\n",
        "feedback_texts = [\n",
        "    \"Excellent product, highly satisfied.\", \"Great quality and fast delivery.\",\n",
        "    \"Works perfectly, no complaints.\", \"Very good experience, easy to use.\",\n",
        "    \"Happy with my purchase.\", \"The item arrived quickly and safely.\",\n",
        "    \"Fantastic value for money.\", \"Couldn't ask for a better service.\",\n",
        "    \"Good design and sturdy build.\", \"Definitely recommend this.\",\n",
        "    \"This is a great feedback.\", \"Another good review.\", \"Top notch!\", \"Flawless.\", \"Super!\",\n",
        "    \"Terrible product, completely broken.\", \"Awful experience, very disappointed.\",\n",
        "    \"Did not work as advertised.\", \"Poor quality and slow shipping.\",\n",
        "    \"Very bad, waste of money.\", \"The product arrived damaged.\",\n",
        "    \"Not worth the price at all.\", \"Customer service was unhelpful.\",\n",
        "    \"Flimsy and cheaply made.\", \"Would not buy again.\",\n",
        "    \"This is a bad feedback.\", \"Another bad review.\", \"Horrible!\", \"Useless.\", \"Fail!\",\n",
        "    \"Excellent product, highly satisfied.\", \"Great quality and fast delivery.\",\n",
        "    \"Works perfectly, no complaints.\", \"Very good experience, easy to use.\",\n",
        "    \"Happy with my purchase.\", \"The item arrived quickly and safely.\",\n",
        "    \"Fantastic value for money.\", \"Couldn't ask for a better service.\",\n",
        "    \"Good design and sturdy build.\", \"Definitely recommend this.\",\n",
        "    \"This is a great feedback.\", \"Another good review.\", \"Top notch!\", \"Flawless.\", \"Super!\",\n",
        "    \"Terrible product, completely broken.\", \"Awful experience, very disappointed.\",\n",
        "    \"Did not work as advertised.\", \"Poor quality and slow shipping.\",\n",
        "    \"Very bad, waste of money.\", \"The product arrived damaged.\",\n",
        "    \"Not worth the price at all.\", \"Customer service was unhelpful.\",\n",
        "    \"Flimsy and cheaply made.\", \"Would not buy again.\",\n",
        "    \"This is a bad feedback.\", \"Another bad review.\", \"Horrible!\", \"Useless.\", \"Fail!\",\n",
        "    \"Excellent product, highly satisfied.\", \"Great quality and fast delivery.\",\n",
        "    \"Works perfectly, no complaints.\", \"Very good experience, easy to use.\",\n",
        "    \"Happy with my purchase.\", \"The item arrived quickly and safely.\",\n",
        "    \"Fantastic value for money.\", \"Couldn't ask for a better service.\",\n",
        "    \"Good design and sturdy build.\", \"Definitely recommend this.\",\n",
        "    \"This is a great feedback.\", \"Another good review.\", \"Top notch!\", \"Flawless.\", \"Super!\",\n",
        "    \"Terrible product, completely broken.\", \"Awful experience, very disappointed.\",\n",
        "    \"Did not work as advertised.\", \"Poor quality and slow shipping.\",\n",
        "    \"Very bad, waste of money.\", \"The product arrived damaged.\",\n",
        "    \"Not worth the price at all.\", \"Customer service was unhelpful.\",\n",
        "    \"Flimsy and cheaply made.\", \"Would not buy again.\",\n",
        "    \"This is a bad feedback.\", \"Another bad review.\", \"Horrible!\", \"Useless.\", \"Fail!\"\n",
        "]\n",
        "feedback_labels = ['good'] * (len(feedback_texts) // 2) + ['bad'] * (len(feedback_texts) // 2) # Ensure equal lengths\n",
        "feedback_df = pd.DataFrame({'Text': feedback_texts, 'Label': feedback_labels})\n",
        "print(\"Synthetic Product Feedback DataFrame (first 5 rows):\\n\", feedback_df.head())\n",
        "print(\"Label distribution:\\n\", feedback_df['Label'].value_counts())\n",
        "\n",
        "# Preprocess the text using TfidfVectorizer with a maximum of 300 features,\n",
        "# applying lowercasing and stop word removal.\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=300, lowercase=True, stop_words='english')\n",
        "X_feedback = tfidf_vectorizer.fit_transform(feedback_df['Text'])\n",
        "y_feedback = feedback_df['Label']\n",
        "print(\"Shape of TF-IDF vectorized data:\", X_feedback.shape)\n",
        "\n",
        "# Split the dataset into training (75%) and testing (25%) sets.\n",
        "X_train_feedback, X_test_feedback, y_train_feedback, y_test_feedback = train_test_split(\n",
        "    X_feedback, y_feedback, test_size=0.25, random_state=42\n",
        ")\n",
        "print(f\"Training set size: {X_train_feedback.shape[0]}, Test set size: {X_test_feedback.shape[0]}\")\n",
        "\n",
        "# Train a Logistic Regression model on the vectorized training data and print the precision,\n",
        "# recall, and F1-score for the test set.\n",
        "model_lr = LogisticRegression(random_state=42)\n",
        "model_lr.fit(X_train_feedback, y_train_feedback)\n",
        "y_pred_lr = model_lr.predict(X_test_feedback)\n",
        "\n",
        "precision = precision_score(y_test_feedback, y_pred_lr, pos_label='good')\n",
        "recall = recall_score(y_test_feedback, y_pred_lr, pos_label='good')\n",
        "f1 = f1_score(y_test_feedback, y_pred_lr, pos_label='good')\n",
        "\n",
        "print(f\"Logistic Regression - Precision: {precision:.2f}\")\n",
        "print(f\"Logistic Regression - Recall: {recall:.2f}\")\n",
        "print(f\"Logistic Regression - F1-score: {f1:.2f}\")\n",
        "\n",
        "# Write a Python function text_preprocess_vectorize(texts, vectorizer) that\n",
        "# takes a list of text samples and a fitted TfidfVectorizer, and returns the vectorized feature matrix.\n",
        "def text_preprocess_vectorize(texts, vectorizer):\n",
        "    if not isinstance(texts, list) or not all(isinstance(s, str) for s in texts):\n",
        "        raise ValueError(\"Input 'texts' must be a list of strings.\")\n",
        "    if not isinstance(vectorizer, TfidfVectorizer):\n",
        "        raise ValueError(\"Input 'vectorizer' must be a fitted TfidfVectorizer.\")\n",
        "\n",
        "    return vectorizer.transform(texts)\n",
        "\n",
        "# Test the text_preprocess_vectorize function\n",
        "sample_texts = [\"This is a neutral product review.\", \"Absolutely love it, fantastic!\"]\n",
        "vectorized_sample = text_preprocess_vectorize(sample_texts, tfidf_vectorizer)\n",
        "print(\"Shape of vectorized sample texts:\", vectorized_sample.shape)\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nAvZi5Gu2KA",
        "outputId": "63aa572f-661f-44ab-ce58-1be0eef54777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic Product Feedback DataFrame (first 5 rows):\n",
            "                                    Text Label\n",
            "0  Excellent product, highly satisfied.  good\n",
            "1      Great quality and fast delivery.  good\n",
            "2       Works perfectly, no complaints.  good\n",
            "3    Very good experience, easy to use.  good\n",
            "4               Happy with my purchase.  good\n",
            "Label distribution:\n",
            " Label\n",
            "good    45\n",
            "bad     45\n",
            "Name: count, dtype: int64\n",
            "Shape of TF-IDF vectorized data: (90, 62)\n",
            "Training set size: 67, Test set size: 23\n",
            "Logistic Regression - Precision: 0.36\n",
            "Logistic Regression - Recall: 0.42\n",
            "Logistic Regression - F1-score: 0.38\n",
            "Shape of vectorized sample texts: (2, 62)\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}