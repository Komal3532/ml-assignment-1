# -*- coding: utf-8 -*-
"""untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/Komal3532/16853b739d1c793b631e6187be33e630/untitled8.ipynb
"""

import numpy as np

# Generate array
array_2d = np.random.randint(1, 51, size=(5, 4))
print("Array:\n", array_2d)

anti_diag = [array_2d[i, -1 - i] for i in range(min(array_2d.shape))]
print("Anti-diagonal:", anti_diag)

# Max in each row
row_max = np.max(array_2d, axis=1)
print("Max values in each row:", row_max)

# Elements <= overall mean
mean_val = np.mean(array_2d)
less_than_mean = array_2d[array_2d <= mean_val]
print("Elements ≤ mean:", less_than_mean)

# Boundary traversal
def numpy_boundary_traversal(matrix):
    return list(matrix[0]) + list(matrix[1:-1, -1]) + list(matrix[-1][::-1]) + list(matrix[-2:0:-1, 0])

print("Boundary traversal:", numpy_boundary_traversal(array_2d))

# 1D array of random floats
array_1d = np.random.uniform(0, 10, 20)
array_rounded = np.round(array_1d, 2)
print("Rounded array:", array_rounded)

# Statistics
print("Min:", np.min(array_rounded))
print("Max:", np.max(array_rounded))
print("Median:", np.median(array_rounded))

# Replace < 5 with squares
modified_array = np.where(array_rounded < 5, array_rounded**2, array_rounded)
print("Modified array:", modified_array)

# Alternate sort
def numpy_alternate_sort(array):
    sorted_array = np.sort(array)
    result = []
    left, right = 0, len(sorted_array) - 1
    while left <= right:
        result.append(sorted_array[left])
        left += 1
        if left <= right:
            result.append(sorted_array[right])
            right -= 1
    return np.array(result)

print("Alternate sorted array:", numpy_alternate_sort(array_rounded))

import pandas as pd
import random

names = [f"Student{i}" for i in range(1, 11)]
subjects = random.choices(['Math', 'Science', 'English'], k=10)
scores = np.random.randint(50, 101, 10)

# Grade assignment
grades = []
for score in scores:
    if score >= 90: grades.append("A")
    elif score >= 80: grades.append("B")
    elif score >= 70: grades.append("C")
    elif score >= 60: grades.append("D")
    else: grades.append("F")

df = pd.DataFrame({'Name': names, 'Subject': subjects, 'Score': scores, 'Grade': grades})
print(df)

# Sorted DataFrame
print("Sorted by Score:\n", df.sort_values(by='Score', ascending=False))

# Average score by subject
print("Average score per subject:\n", df.groupby('Subject')['Score'].mean())

# Filter function
def pandas_filter_pass(dataframe):
    return dataframe[dataframe['Grade'].isin(['A', 'B'])]

print("Students with A or B:\n", pandas_filter_pass(df))

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

# Create synthetic dataset
np.random.seed(42)

# Positive reviews
positive_reviews = [
    "This movie was absolutely fantastic! The acting was superb.",
    "I loved every minute of this film. The plot was engaging.",
    "A masterpiece of cinema that will stand the test of time.",
    "The director did an amazing job with this production.",
    "One of the best movies I've seen this year, highly recommended!",
    "The cinematography was breathtaking and the story compelling.",
    "A perfect blend of action, drama, and comedy. Wonderful!",
    "The performances were outstanding across the board.",
    "I was completely immersed from start to finish. Brilliant!",
    "This film exceeded all my expectations. Stunning visuals.",
    "An emotional rollercoaster that left me speechless.",
    "The character development was exceptional and moving.",
    "A true work of art that deserves all the awards.",
    "I couldn't take my eyes off the screen. Magnificent!",
    "The soundtrack perfectly complemented the storytelling.",
    "Fresh and original take on a familiar genre. Loved it!",
    "The chemistry between the leads was electric.",
    "A thought-provoking film that stays with you long after.",
    "Perfect pacing and never a dull moment. Superb!",
    "The visual effects were groundbreaking and realistic.",
    "A heartwarming story that touched my soul.",
    "The dialogue was sharp, witty, and meaningful.",
    "A cinematic triumph that deserves recognition.",
    "I laughed, I cried, I cheered. What more could you want?",
    "The best of its genre in recent memory. Flawless.",
    "A powerful narrative with incredible performances.",
    "The atmosphere created was utterly captivating.",
    "A rare gem that delivers on every level.",
    "The ending was perfect and deeply satisfying.",
    "A must-see for any true film enthusiast.",
    "The attention to detail was remarkable throughout.",
    "A beautiful film that celebrates the human spirit.",
    "I was on the edge of my seat the entire time.",
    "The direction was confident and visionary.",
    "A refreshing change from typical Hollywood fare.",
    "The movie had me hooked from the opening scene.",
    "A perfect balance of style and substance.",
    "The emotional depth was astonishing. Bravo!",
    "A film that will be remembered for generations.",
    "The production design was imaginative and immersive.",
    "A tour de force that showcases the best of cinema.",
    "I was completely blown away by this movie.",
    "The script was clever and full of surprises.",
    "A moving portrait that resonates deeply.",
    "The action sequences were thrilling and well-choreographed.",
    "A profound meditation on life and relationships.",
    "The humor was spot-on and never felt forced.",
    "A visually stunning achievement in filmmaking.",
    "I can't stop thinking about this movie. Phenomenal!"
]

# Negative reviews
negative_reviews = [
    "This was the worst movie I've ever seen. Terrible acting.",
    "A complete waste of time. The plot made no sense.",
    "I couldn't wait for it to end. Painfully boring.",
    "The dialogue was cringe-worthy and unrealistic.",
    "Avoid at all costs. A total disaster of a film.",
    "The characters were unlikeable and poorly developed.",
    "A soulless cash grab with no originality.",
    "The pacing was awful and dragged endlessly.",
    "I walked out halfway through. Just terrible.",
    "The special effects looked cheap and fake.",
    "A confusing mess with no coherent storyline.",
    "The acting was wooden and unconvincing.",
    "A pretentious attempt at art that falls flat.",
    "The worst adaptation I've ever witnessed.",
    "Full of clichés and predictable twists.",
    "The director clearly had no vision for this project.",
    "A complete misfire on every possible level.",
    "I regret spending money on this garbage.",
    "The soundtrack was distracting and inappropriate.",
    "A hollow shell of what it could have been.",
    "The cinematography was dull and uninspired.",
    "A failed experiment that shouldn't have been released.",
    "The editing was jarring and inconsistent.",
    "Not a single redeeming quality in this mess.",
    "The script was full of plot holes and nonsense.",
    "A tedious experience with no payoff.",
    "The lead actor was completely miscast.",
    "A derivative work with nothing new to offer.",
    "The humor fell flat every single time.",
    "A disappointing effort from talented people.",
    "The production values looked shockingly low.",
    "A forgettable film that adds nothing to cinema.",
    "The tone was all over the place and confusing.",
    "A cynical attempt to cash in on a trend.",
    "The emotional moments felt forced and unearned.",
    "A technical disaster with bad sound mixing.",
    "The runtime felt three times as long as it was.",
    "A complete misunderstanding of the source material.",
    "The climax was underwhelming and anticlimactic.",
    "A movie that insults the audience's intelligence.",
    "The characters made decisions that made no sense.",
    "A waste of a talented cast on a bad script.",
    "The visuals were dated and unimpressive.",
    "A soulless corporate product with no heart.",
    "The plot twists were telegraphed from miles away.",
    "A film that can't decide what it wants to be.",
    "The ending was unsatisfying and rushed.",
    "A collection of bad ideas poorly executed.",
    "The movie couldn't maintain any tension.",
    "I've never been so bored in a theater before."
]

# Create DataFrame
reviews = positive_reviews + negative_reviews
sentiments = ['positive'] * len(positive_reviews) + ['negative'] * len(negative_reviews)

df = pd.DataFrame({
    'Review': reviews,
    'Sentiment': sentiments
})

# Shuffle the dataset
df = df.sample(frac=1, random_state=42).reset_index(drop=True)

# 1. Tokenize the reviews using CountVectorizer
vectorizer = CountVectorizer(max_features=500, stop_words='english')
X = vectorizer.fit_transform(df['Review'])
y = df['Sentiment']

# 2. Split the dataset
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 3. Train a Multinomial Naive Bayes classifier
model = MultinomialNB()
model.fit(X_train, y_train)

# Predict and print accuracy
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Model accuracy on test set: {accuracy:.2f}")

# 4. Prediction function
def predict_review_sentiment(model, vectorizer, review):
    """
    Predict the sentiment of a single review.

    Parameters:
    model -- trained classifier model
    vectorizer -- fitted CountVectorizer
    review -- string containing the review text

    Returns:
    string -- 'positive' or 'negative' sentiment prediction
    """
    # Vectorize the review
    review_vec = vectorizer.transform([review])
    # Predict sentiment
    prediction = model.predict(review_vec)
    return prediction[0]

# Example usage
test_review = "This movie was a wonderful experience from start to finish."
prediction = predict_review_sentiment(model, vectorizer, test_review)
print(f"\nExample prediction for positive review: {prediction}")

test_review = "I hated every minute of this awful film."
prediction = predict_review_sentiment(model, vectorizer, test_review)
print(f"Example prediction for negative review: {prediction}")

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, recall_score, f1_score
import pandas as pd # Import pandas



# Create a synthetic dataset of 100 short text samples (e.g., product feedback) with binary labels (good/bad)
# and apply an NLP pipeline using scikit-learn.
feedback_texts = [
    "Excellent product, highly satisfied.", "Great quality and fast delivery.",
    "Works perfectly, no complaints.", "Very good experience, easy to use.",
    "Happy with my purchase.", "The item arrived quickly and safely.",
    "Fantastic value for money.", "Couldn't ask for a better service.",
    "Good design and sturdy build.", "Definitely recommend this.",
    "This is a great feedback.", "Another good review.", "Top notch!", "Flawless.", "Super!",
    "Terrible product, completely broken.", "Awful experience, very disappointed.",
    "Did not work as advertised.", "Poor quality and slow shipping.",
    "Very bad, waste of money.", "The product arrived damaged.",
    "Not worth the price at all.", "Customer service was unhelpful.",
    "Flimsy and cheaply made.", "Would not buy again.",
    "This is a bad feedback.", "Another bad review.", "Horrible!", "Useless.", "Fail!",
    "Excellent product, highly satisfied.", "Great quality and fast delivery.",
    "Works perfectly, no complaints.", "Very good experience, easy to use.",
    "Happy with my purchase.", "The item arrived quickly and safely.",
    "Fantastic value for money.", "Couldn't ask for a better service.",
    "Good design and sturdy build.", "Definitely recommend this.",
    "This is a great feedback.", "Another good review.", "Top notch!", "Flawless.", "Super!",
    "Terrible product, completely broken.", "Awful experience, very disappointed.",
    "Did not work as advertised.", "Poor quality and slow shipping.",
    "Very bad, waste of money.", "The product arrived damaged.",
    "Not worth the price at all.", "Customer service was unhelpful.",
    "Flimsy and cheaply made.", "Would not buy again.",
    "This is a bad feedback.", "Another bad review.", "Horrible!", "Useless.", "Fail!",
    "Excellent product, highly satisfied.", "Great quality and fast delivery.",
    "Works perfectly, no complaints.", "Very good experience, easy to use.",
    "Happy with my purchase.", "The item arrived quickly and safely.",
    "Fantastic value for money.", "Couldn't ask for a better service.",
    "Good design and sturdy build.", "Definitely recommend this.",
    "This is a great feedback.", "Another good review.", "Top notch!", "Flawless.", "Super!",
    "Terrible product, completely broken.", "Awful experience, very disappointed.",
    "Did not work as advertised.", "Poor quality and slow shipping.",
    "Very bad, waste of money.", "The product arrived damaged.",
    "Not worth the price at all.", "Customer service was unhelpful.",
    "Flimsy and cheaply made.", "Would not buy again.",
    "This is a bad feedback.", "Another bad review.", "Horrible!", "Useless.", "Fail!"
]
feedback_labels = ['good'] * (len(feedback_texts) // 2) + ['bad'] * (len(feedback_texts) // 2) # Ensure equal lengths
feedback_df = pd.DataFrame({'Text': feedback_texts, 'Label': feedback_labels})
print("Synthetic Product Feedback DataFrame (first 5 rows):\n", feedback_df.head())
print("Label distribution:\n", feedback_df['Label'].value_counts())

# Preprocess the text using TfidfVectorizer with a maximum of 300 features,
# applying lowercasing and stop word removal.
tfidf_vectorizer = TfidfVectorizer(max_features=300, lowercase=True, stop_words='english')
X_feedback = tfidf_vectorizer.fit_transform(feedback_df['Text'])
y_feedback = feedback_df['Label']
print("Shape of TF-IDF vectorized data:", X_feedback.shape)

# Split the dataset into training (75%) and testing (25%) sets.
X_train_feedback, X_test_feedback, y_train_feedback, y_test_feedback = train_test_split(
    X_feedback, y_feedback, test_size=0.25, random_state=42
)
print(f"Training set size: {X_train_feedback.shape[0]}, Test set size: {X_test_feedback.shape[0]}")

# Train a Logistic Regression model on the vectorized training data and print the precision,
# recall, and F1-score for the test set.
model_lr = LogisticRegression(random_state=42)
model_lr.fit(X_train_feedback, y_train_feedback)
y_pred_lr = model_lr.predict(X_test_feedback)

precision = precision_score(y_test_feedback, y_pred_lr, pos_label='good')
recall = recall_score(y_test_feedback, y_pred_lr, pos_label='good')
f1 = f1_score(y_test_feedback, y_pred_lr, pos_label='good')

print(f"Logistic Regression - Precision: {precision:.2f}")
print(f"Logistic Regression - Recall: {recall:.2f}")
print(f"Logistic Regression - F1-score: {f1:.2f}")

# Write a Python function text_preprocess_vectorize(texts, vectorizer) that
# takes a list of text samples and a fitted TfidfVectorizer, and returns the vectorized feature matrix.
def text_preprocess_vectorize(texts, vectorizer):
    if not isinstance(texts, list) or not all(isinstance(s, str) for s in texts):
        raise ValueError("Input 'texts' must be a list of strings.")
    if not isinstance(vectorizer, TfidfVectorizer):
        raise ValueError("Input 'vectorizer' must be a fitted TfidfVectorizer.")

    return vectorizer.transform(texts)

# Test the text_preprocess_vectorize function
sample_texts = ["This is a neutral product review.", "Absolutely love it, fantastic!"]
vectorized_sample = text_preprocess_vectorize(sample_texts, tfidf_vectorizer)
print("Shape of vectorized sample texts:", vectorized_sample.shape)
print("-" * 30)